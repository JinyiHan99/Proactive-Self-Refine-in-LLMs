eval_prompt_config= {
"sum_type": '''Now, I want to test an AI assistant's ability to summary.
Below is a text(Question), a ground truth summary(Ground Truth Answer), and an answer(Answer) generated by an AI assistant.
Please rate the AI assistant's answers according to the ground truth answer.
Please score answers according to how relevant they are to the text and ground truth summary
Your output is from 0 to 1,which 0 is not similar at all, 1 is basically error free.''',

"multi_choice_type": '''Now, I want to test an AI assistant's ability to answer questions.
Below is a mutlti-choice question, a ground truth answer(one of the option), and an answer generated by an AI assistant.
Please rate the AI assistant's answers according to the question and the ground truth answer.
If you think the answer is correct, your output is 1; otherwise, your output is 0.
Your output is just 0 or 1.''',

"general_type": '''Now, I want to test an AI assistant's ability to answer questions.
Below is a question, a ground truth answer, and an answer generated by an AI assistant.
Please rate the AI assistant's answers according to the ground truth answer.
If you think the answer is correct, your output is 1; otherwise, your output is 0.
Your output is just 0 or 1.'''
}


revise_prompt_config={
    "second_revise_w_oracle_math_type":"There might be an error in the solution above because of lack of understanding of the question. Please correct the error, if any, and rewrite the solution. Only output the final solution! At the end of the Solution, when you give your final answer, write it in the form 'Final Answer: The final answer is \\box{answer}. I hope it is correct.'",
    "second_revise_w_oracle_code_type":" There might be an error in the code above because of lack of understanding of the question. Please correct the error, if any, and rewrite the solution. Only output the final correct Python program!",
    "second_revise_w_oracle_general": "There is an error in the previous solution. Please review each step to identify the mistake, and then provide a corrected version of the solution",
    
    "second_revise_without_oracle": "Please review each step of the previous solution to identify any potential errors. If you find any issues, provide a revised and corrected version of the solution. If there are no issues, simply respond with: 'I believe the above solution is correct."
}

gen_prompt_config= {
    "first_gen_mmlu": "Here is a multiple-choice question, which from a dataset tests knowledge across 57 diverse fields such as elementary mathematics, history, computer science, and law. please think step by step and give me your final answer. \n",
    "first_gen_humaneval": "Please think step by step to complete the python function and output the entire function within a python code block. \n",
    "first_gen_drop": "Here is a passage and a question, which requires discrete reasoning over the provided text. Please think step by step and give me your final answer. \n",
    "first_gen_xsum": "Here is a passage. please summarize this passage. \n",
    "first_gen_math": "Here is a problem. please think step by step and give me your final answer. \n",
    "first_gen_arc": "Here is a multiple-choice question, which from a collection of questions for the science exam. Please think step by step and give me your final answer. \n",
    "first_gen_gpqa": "",
    "first_gen_wino": "Here is a question provides two options. Please think step by step and select the correct answer based on the semantics of the sentence. \n",
    "first_gen_commonsenseqa": "Here is multiple-choice about commonsense. Please think step by step and give me your final answer."
}